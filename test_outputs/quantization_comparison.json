{
  "float16": {
    "model_size_gb": 4.620043776,
    "load_time": 27.9652361869812,
    "avg_inference_time": 8.922664483388266,
    "avg_tokens_per_second": 0.0,
    "avg_rtf": 0.5814423754867226,
    "errors": []
  },
  "int4": {
    "model_size_gb": 0,
    "load_time": 0,
    "avg_inference_time": 0,
    "avg_tokens_per_second": 0,
    "avg_rtf": 0,
    "errors": [
      "Failed to load LLAMA model: Error(s) in loading state_dict for DualARTransformer:\n\tsize mismatch for layers.0.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.0.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.0.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.0.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.0.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.1.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.1.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.1.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.1.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.1.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.2.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.2.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.2.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.2.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.2.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.3.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.3.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.3.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.3.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.3.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.4.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.4.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.4.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.4.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.4.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.5.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.5.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.5.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.5.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.5.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.6.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.6.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.6.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.6.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.6.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.7.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.7.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.7.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.7.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.7.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.8.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.8.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.8.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.8.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.8.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.9.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.9.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.9.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.9.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.9.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.10.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.10.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.10.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.10.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.10.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.11.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.11.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.11.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.11.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.11.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.12.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.12.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.12.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.12.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.12.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.13.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.13.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.13.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.13.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.13.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.14.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.14.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.14.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.14.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.14.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.15.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.15.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.15.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.15.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.15.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.16.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.16.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.16.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.16.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.16.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.17.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.17.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.17.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.17.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.17.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.18.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.18.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.18.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.18.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.18.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.19.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.19.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.19.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.19.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.19.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.20.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.20.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.20.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.20.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.20.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.21.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.21.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.21.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.21.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.21.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.22.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.22.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.22.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.22.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.22.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.23.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.23.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.23.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.23.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.23.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.24.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.24.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.24.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.24.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.24.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.25.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.25.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.25.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.25.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.25.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.26.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.26.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.26.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.26.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.26.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for layers.27.attention.wqkv.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]).\n\tsize mismatch for layers.27.attention.wo.weight: copying a param with shape torch.Size([128, 32, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 16, 32, 4]).\n\tsize mismatch for layers.27.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.27.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for layers.27.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([19472, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([19472, 8, 32, 4]).\n\tsize mismatch for fast_layers.0.attention.wqkv.weight: copying a param with shape torch.Size([256, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([256, 8, 32, 4]).\n\tsize mismatch for fast_layers.0.attention.wo.weight: copying a param with shape torch.Size([128, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 8, 32, 4]).\n\tsize mismatch for fast_layers.0.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for fast_layers.0.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for fast_layers.0.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for fast_layers.1.attention.wqkv.weight: copying a param with shape torch.Size([256, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([256, 8, 32, 4]).\n\tsize mismatch for fast_layers.1.attention.wo.weight: copying a param with shape torch.Size([128, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 8, 32, 4]).\n\tsize mismatch for fast_layers.1.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for fast_layers.1.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for fast_layers.1.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for fast_layers.2.attention.wqkv.weight: copying a param with shape torch.Size([256, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([256, 8, 32, 4]).\n\tsize mismatch for fast_layers.2.attention.wo.weight: copying a param with shape torch.Size([128, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 8, 32, 4]).\n\tsize mismatch for fast_layers.2.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for fast_layers.2.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for fast_layers.2.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for fast_layers.3.attention.wqkv.weight: copying a param with shape torch.Size([256, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([256, 8, 32, 4]).\n\tsize mismatch for fast_layers.3.attention.wo.weight: copying a param with shape torch.Size([128, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 8, 32, 4]).\n\tsize mismatch for fast_layers.3.feed_forward.w1.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for fast_layers.3.feed_forward.w3.weight: copying a param with shape torch.Size([384, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([384, 8, 32, 4]).\n\tsize mismatch for fast_layers.3.feed_forward.w2.weight: copying a param with shape torch.Size([128, 48, 32, 4]) from checkpoint, the shape in current model is torch.Size([128, 24, 32, 4]).\n\tsize mismatch for fast_output.weight: copying a param with shape torch.Size([512, 16, 32, 4]) from checkpoint, the shape in current model is torch.Size([512, 8, 32, 4]). | Details: {'checkpoint_path': 'checkpoints\\\\fs-1.2-int4-g128-20260116_060959'}"
    ]
  }
}