# Voice Service Configuration
# Copy this file to .env and update values

# Server settings
VOICE_HOST=0.0.0.0
VOICE_PORT=8000
VOICE_WORKERS=1
VOICE_LOG_LEVEL=info

# TTS Provider: s1_mini | elevenlabs | mock
VOICE_TTS_PROVIDER=s1_mini

# S1 Mini settings
# Option 1: Download model from HuggingFace automatically
VOICE_S1_DOWNLOAD_MODEL=false
VOICE_S1_MODEL_REPO=fishaudio/openaudio-s1-mini

# Option 2: Use local checkpoint path
# Model should be downloaded to voice-service/checkpoints/openaudio-s1-mini
# Or use absolute path: VOICE_S1_CHECKPOINT_PATH=/absolute/path/to/checkpoints/openaudio-s1-mini
VOICE_S1_CHECKPOINT_PATH=checkpoints/openaudio-s1-mini

VOICE_S1_COMPILE=false
VOICE_S1_DEVICE=cuda
VOICE_S1_HALF=false

# LoRA settings (optional)
VOICE_LORA_ENABLED=false
VOICE_LORA_PATH=

# Reference storage: huggingface | local | s3
VOICE_REFERENCE_STORAGE=local
VOICE_LOCAL_REFERENCE_PATH=references

# HuggingFace storage settings
VOICE_HF_REFERENCE_REPO=
VOICE_HF_TOKEN=

# S3 storage settings (production)
VOICE_S3_BUCKET=
VOICE_S3_PREFIX=references/
VOICE_AWS_REGION=us-east-1

# ElevenLabs settings (fallback)
VOICE_ELEVENLABS_API_KEY=
VOICE_ELEVENLABS_MODEL=eleven_multilingual_v2

# Inference settings
VOICE_MAX_TEXT_LENGTH=2000
VOICE_DEFAULT_CHUNK_LENGTH=200
VOICE_STREAMING_ENABLED=true



